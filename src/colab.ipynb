{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.loadData import loadData\n",
    "from lstm.preprocessing import normalize, convertToClassification, normalizeAtOnce\n",
    "from lstm.model import getModel\n",
    "from lstm.visualization import show_result, visualize_loss, visualize_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Already downloaded using src/utils/fetchStockData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  \n",
    "  df = loadData()\n",
    "except:\n",
    "  print(\"Please, download BTC data. See README.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Normalisation, train/test split and preparing for LSTM processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(df[\"Close\"]).reshape(-1, 1)\n",
    "normalized_data = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.715\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "\n",
    "past = 100\n",
    "future = 14\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "train_data = normalized_data[:train_split]\n",
    "val_data = normalized_data[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data\n",
    "y_train = normalized_data[start:end]\n",
    "\n",
    "dataset_train = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=past,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "x_end = len(val_data) - past - future\n",
    "label_start = train_split + past + future\n",
    "\n",
    "x_val = val_data\n",
    "y_val = normalized_data[label_start:]\n",
    "y_val = convertToClassification(x_val, y_val, past+future)\n",
    "\n",
    "dataset_val = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=past,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "for batch in dataset_val.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel(inputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss(history)\n",
    "visualize_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dataset_val.take(5):\n",
    "    show_result(x, y, future, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I need to make a proper decision on how my hyperparameters are chosen. Speak to Tingting/Jon today if I have questions."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "922f3f0f14de93c55527dbc5ad53b281c54eefd8b075b625f5e98225241459c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('project-56ryZJ7i')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
